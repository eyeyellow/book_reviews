## Some ideas to eventually write about

- Granular convection and why Nate is wrong about coffee grinders

- James C. Scott's aspect of legibility and project management

- Online skins and why the conversation that we're having now is an old conversation

- We're wasting electricity: Using energy to enable garbage content [proto]

- Organic walking paths are the purest of democratic forms

- Would smart contracts make the world even more inuhuman and beureaucratic?

- Bad economic reasoning of trust cases, but also marginal utility arguments

- The pitiful democracy of meetings


Books to review:
- Habaeus data
- The efficiency paradox
- Broad band
- The Curse of Bigness
- Surveillance Valley
- The Shipwrecked Mind
- The Death and Life of the Great Lakes
- Listen Liberal
- Deschooling Society
- The End of Trust
- Anti-Intellectualism in American Life
- Against Method
- Mushroom at the End of the World



Maybe to read (fiction):
- Ben Lerner
- Diane Williams
- László Krasznahorkai
- Robert Walser






1/4/2020

With the beginning of the New Decade, I was thinking that I should start a blog. At first, I thought that it would be nice to have some 'content' to put on the Internet as a means of practicing the craft of designing, architecting, and deploying a blog to the web. The more I think about it though, I just really like to write things down (usually in letters to friends or in rants in chat threads). So I'm doing this for the content more so than for having a side project that I feed content to.

And it also got me thinking - the idea of 'content' kind of sucks.

I don't know about the history of when people started using the word 'content' to describe the material of what we consume on the Internet - separate from the code and infrastructure of the whole thing. In my opinion, the content of the Internet is the whole point of why people go online, but as a web developer it's kind of always a secondary concern. First comes the layout of the page, and the icons and buttons, and all of the form controls, and the color palette and animations, and rounded corners and spacing, and everything. And then what the page is actually going to say is some separate concern. At my current job, it's usually someone else's problem to write the content, though I know there are many content-driven sites for publishing things ('publishing' in the journalistic or analytic sense, not like publishing something to Instagram). But lately I've come to think that content is central to the Internet and kind of always has been.

Sure there's metadata about the content (who's publishing the content, who's sharing it with whom, where are the links in the content directing people, etc.), and there's been a proliferation of services on the web that aren't content-driven (buying things, getting a ride somewhere, meeting new people, etc.), but at the end of the day I feel like people still mostly go online to consume content. By content, I don't mean exclusively written content or even true or useful content. I mean stuff on the web.

The designation of something that we call content kind of waters it down aesthetically. Did Bach compose content? Or did Basquiat paint content? Was Susan Sontag a content writer? Calling something content kind of trivializes it or casts it as an afterthought, like it's some minor industrial feedstock for some finished product that is never your own as the publisher.

I want this blog to be different, but at the end of the day it's still a blog.


some other related ideas (more late)
- Internet is for forms from the Utopia of Rules
- carnegie and consumerism (start w/bullshit jobs)
- git as 'stupid content tracker'
- self-publishing and William Blake






Bullshit Jobs: A Theory by David Graeber
Simon & Schuster 2018

This is one of the best books that I read last year. In it Graeber diagnoses the prevasive but under-discussed phenomenon of bullshit jobs, which he defines as "a form of paid employment that is so completely pointless, unnecessary, or pernicious that even the employee cannot justify its existence even though, as part of the conditions of employment, the employee feels obliged to pretend that this is not the case." What follows is an analysis of the rise of these types of jobs, with research gathered from several interviews with people who believe their jobs are bullshit. Included is a typology of the different kinds of bullshit jobs, along with a historical analysis of the rise of bullshit jobs in modern society.

While the interviews were informative, I found Graeber's historical research to be the most useful part of the book in conceptualizing the rise in bullshit jobs. With the rise of 'managerial feudalism' in various sectors, it's now up to a class of efficiency experts to dictate how jobs get created and a good chunk of these jobs involve doing pointless paperwork report to managers. The network of the managers who report to other managers serves as a means of distributing goods for political purposes inside of businesses, which in the end has nothing to do with the reality of what the given business actually does. Graeber contrasts this with the old feudalism of kings and serfs except that in classical feudalism, there doesn't exist an intermediary class of people to tell the peasants and craftsmen how do go about doing their work.

The larger process in society that has enabled the rise of managers and related bureaucratic professions is the financialization of the world. Specifically, this consists of financial institutions creating money through making loans, and then moving money around in elaborate ways, with some intermediary at each step taking a small cut of it. While I'm sure there are some people that would object to this as over-generalizing, I've seen this to be true in both the private and government sectors. In my former life as a secondary education teacher, I was suprised at seeing the rise in consultants and teacher performance evaluation specialists whose job it was to oversee how good of a teacher I was. I always had a hard time understanding how these bureaucrats had any positive impact on my profession and my students' learning outcomes. Graeber gives a similar example of bureaucracy in higher education. Some people may object that this is just because these are ossified public institutions, and that the private sector does a better job allocating resources to reduce the amount of bureaucratic bullshit jobs. However, I think it's worth pointing out that the rise in unnecessary bureaucracy in primary and secondary education was the result of education reforms under No Child Left Behind (NCLB) to make the education system behave more like a market. Some commentators have pointed out that this in effect has created a sector of 'no consultant left behind', and that modeling the education after the market system is largely a failure. I believe that this stems from the financialization of the education system under NCLB, wherein schools' performance is tied to growth as a function of how much students' test scores improve over time. This financialization of education is the dynamic that Graeber is getting at wherein we have some metric that acts as some indicator of progress that managers within the education system use to allocate monetary resources to each other in a symbolic exchange of value that gives politicians the sense that taxpayers are getting a return on their investment in public services.

While this is just one example that confirm's Graeber's theory of bullshit jobs, I feel like there are several more similar scenarios where the financialization of some sector has given rise to pointless (or potentially harmful) occupations, that the people who hold these occupations loath them. I'm speculating here, but perhaps the increasing financialization of the world will finally do itself in, as more bullshit jobs continue to crop up and what seems like a radical idea now becomes a future talking point for social reformers in doing away with the vapid and oppressive 40-hour work week.

[1/18/20]


__Some notes__
- Doing a craft as meaningful output vs. being a rented slave where you're selling your time - fixed pieces of time sold for money p. 91
- Rise in administrative apparatus (universities example p. 162), as result of financialization of institutions creates bureaucracy
  - Create money by making loans, and then moving money around in elaborate ways, taking small cuts of it p. 167
- Managerial feudalism - like in old feudalism, extract goods from peasants and craftsmen and distribute them for political purposes - portion out shares of the loot (p. 176)
  - managerial is similar in that it's distributed across managers, but the managers also govern and get in the way of how people in autonomous trades should do their jobs ('efficiency experts' p. 178
- 'producerism' as puritan moral superiority of the work over the idle rich - then andrew carnegie switches peoples' minds to 'consumerism' of productivity of capital over labor
  - wise stewardship over capital so that prices could be lowered to benefit consumers - consumers live like kings p. 233 (qtd from )
- voluntariat labor of software engineers who work for free on open source projects for the passion of it, but then companies hire people to duct tape those projects together p. 219
- Most historically working class jobs actually consisted of taking care of people, tending to peoples needs, reassuring, explaining etc. p. 235
  - What tube workers actually do is caring labor - interpretation, empathy, and understanding
  - All labor is caring labor - if you build a bridge, it's because someone cared about it p. 237
  - When you star thinking of work 'productive', then you think of workers as no different than the machines that they operate
- Obama's smoking gun on healthcare, and why private insurance partially exists to give people jobs working for insurance companies p. 157
- 'misery of not being entitled to misery', and rights-scolding p. 127
- 'misery of knowing one is doing harm' - as it relates to social work in institutions (personal aside) p. 131




The Curse of Bigness: Antitrust in the New Gilded Age by Tim Wu
Columbia Global Reports 2018


In The Curse of Bigness, Tim Wu makes the case for re-imagining the definition of anti-trust in the modern era. Wu argues that anti-trust has always been about limiting the political influence of private power on government and citizens, but in the past few decades anti-trust has been narrowly redefined to only apply to a limited case of consumer welfare based off of faulty price theory.

This notion of using price theory to say that 'According to this economic model, businesses won't behave this way under given conditions, therefore let's as a society give them these conditions, and we should all be fine' is a faulty one that I've encountered in economic literature. Price theory as applied to anti-trust law imagines monopolies as naturally restrained through the prices that they've arrived at for certain goods via market forces pushing them towards efficiency. Therefore, as long as monopolies aren't hurting consumers through the wrong prices, then there's nothing to see here as far as prosecution goes. I see this as a pattern in how economists reify problems of politics into some arbitrary metric - in this case how much goods cost. What concerns me is how these fautly models dictate the legal actions that can be taken against monopolies in anti-trust cases. Wu argues that anti-trust has always been about politics, and he gives various pieces of evidence from the last century of these anti-trust cases taking a constitutional role in protecting people against unchecked private power. In this Gilded Age pattern that we've seen reemerging in the last few decades, what happens is that industry groups gain enough political power to undermine democratic majorities in influencing government policy, followed by private interests rivaling the governments themselves in terms of power. This phenomenon should overshadow pricing theory in terms of how to accurately assess the influence of monopolies.

The counterargument of taking such explicit political power into consideration is that it's hard to quantify these phenomena in any scientific way. This comes from the Chicago School of anti-trust analysis that takes only prices into consideration. There's an additional appeal to conservatives in this limited Chicago School approach in that it prevents 'judicial activists' from interpreting anti-trust cases too loosely, and letting politics come into play. Wu makes a solid case for the contrary view that in deciding to interpret the law this way and to narrowly focus on prices is in fact a political decision.

I think that as a society we should abandon these pseudo-scientific models of markets, and start asking ourselves the hard questions of how we're going to limit the growing role of businesses over democracy. Otherwise, capital will create a shadow government eclipses democracy, and economists will look at the price we pay for things as a stronger indicator of social progress than the strength our votes.

[1/26/20]


__Some notes__
- Making the case for anti-trust - was big a half century ago, but has waned within a generation
  - Rescue anti-trust law from the narrowly-defined interpretation of scoping it to effect on prices (Robert Bork)
  - Scientific rigor, but applied to 'consumer wellfare'
  - Robert Pitofsky - bad policy to exclude political values in this interpretation p. 17
- Political anti-trust - constitutional role in protecting against private power (checks and balances)
  - But it will give rise to anti-democratic political pressure - private power becomes rival to government
  - Majorities in democracies loose out to small industry-backed interest groups p. 55
  - Examples of concentration of chemical industry instrumental in bringing Nazis to power p. 80
  - Counter argument being that political values are too political to be considered by the courts
    - Trope of 'judicial activists' that may in with their values
    - Otherwise makes judges jobs easier - Can you prove that it hurt consumers? etc p. 90
    - Monopolies are naturally restrained - they found the perfect/efficient form via pricing theory
      - Disregard to considering other ways they might hurt their competition though
    - Therefore, according to the theory they shouldn't misbehave
    - That's not the case though
    - Interpreting it in this way is inherently political p. 107



Broad Band: The Untold Story of the Women Who Made the Internet by Claire L. Evans
Portfolio/Pengium 2018


After reading Broad Band by Claire L. Evans, I was suprised to discover how little I knew about the role women have played in advancing the field of computer science. If you would have asked me to drop the names of famous women programmers, and summarize their contributions, I would have said Ada Lovelace and Grace Hopper with maybe a vague idea of what their work consisted of. After reading Broad Band, I learned that programmers like Grace Hopper have contributed much more than the field that we often give them credit for, and it turns out that Hopper wasn't the only 20th century female programmer worth noting.

I feel that we can learn valuable lessons from Grace Hopper's life. Sure she wrote the first ever compiler and she practically invented subroutines when she was working on the Mark I computer at Harvard in the 1940s. Something that I didn't know about her was that she commented and wrote about her code extensively in order to share it with other people. Evans suggests that this comes from her days of teaching at Vassar, where Hopper would require students to write essays about their mathematics problems, as Hopper believed that there's no use in learning math if you can't explain it to someone else. I have found that this is often the case in modern programming, where code comments and documentation help facillitate collaboration of writing software. Evans suggests that this 'soft skills' role of communicating ideas and specifications of sofware is something that allowed early female programmers to excel in the field. I feel like this is an important point even for modern teams, since at the end of the day the real world is messy and you'll have to anticipate the needs of non-techincal team members or end users to understand how to use your program.

Another impressive figure in early programming who I hadn't heard of before was Betty Holberton. While working on UNIVAC for Eckert–Mauchly Computer Corporation, Holberton wrote the Sort Merge Generator, which took input specifications of files and operations to use, and it outputs machine code. This was the first computer program that wrote other computer programs — paving the way for future advances in compilers. Holberton also helped design the C-10 instruction set, which became the earliest example of machine code abstracted into a programming language. Holberton and Hopper also went on to help develop the speficications for COBOL, one of the earliest high-level programming languages used across different machines.

As notable as these mid-century innovations are, Evans profiles later innovators — including Jake Feinler (manager of ARPANET's registry of hosts before DNS existed), Radia Perlman (inventor of the Spanning Tree Protocol for resolving redundancies in routing packets other ethernet), and Wendy Hall and Cathy Marshall (early authors of pre-World Wide Web hypermedia systems for linking metadata of resources). The book does a good job profiling not just the techical innovators, but the cutural innovators of the early Internet too.

These kinds of histories make me think about the next generation of women innovating to further the development of the Internet.



__Some notes__
General theme - impressed by Grace Hopper's contributions to programming
- Invention of subroutines - she wrote them down in notebooks to share with others 1944 (p. 37)
  - Began commenting in the code, similar to when she was teaching at Vassar - get students to write essays about math problems
  - Democratize the field
  - No reason to learn if you can't communicate it
  - All with Mark I at Harvard for ballistics calculations
- ENIAC Six
  - At Moore School of Electrical Engineering at University of Pennsylvania
  - Electronic Numerical Integrator and Computer
  - Different from Mark 1, as it takes bunch of time to set up, thought actual calculation is quicker than Mark 1
  - Kathleen McNulty, Betty Jean Jennings, Elizabeth Snyder, Marlyn Wescoff, Frances Bilaf, and Ruth Lichterman (p. 39)
  - All collaborated on an early demonstration of it
- Eckert-Mauchly Computer Corporation
  - Betty Holberton - developed C-10 instruction set for UNIVAC at EMCC (p. 59)
  - Machines can modify instructions along the way - no longer linear code
  - Sort Merge Generator - input specifications of files and operations to use, and it outputs machine code 
    - First case of writing a program that wrote a program
  - Grace Hopper - first compiler A-0
    - Compile selected subroutines, and then arrange and translate them into machine code (p. 67)
    - Makes it so you don't have to worry about the nitty gritty details
    - Removes human error from the process
- Role of women facillitating communication - getting specifications right (p. 78)
  - Parse messiness of real-world problems into executable programs
  - Anticipate the needs of non-technical users
- Jake Feinler - Network Information Center Handbook pre-DNS (p. 113)
  - Managed ARPANET's registry - "Host Table"
- Radia Perlman - Spanning Tree Protocol (p. 126)
  - Prevent loops in network topology - routes packets without redundancies
  - If computer goes down, protocol determines a new route for the packet
- Wendy Hall - Invented a hypermedia system for linking archival documents that predated the World Wide Web
  - Created a 'linkbase' of metadata for linking documents at University of Southampton
Cathy Marshall - Invented hypermedia system of linking resource (via 'cards' - HyperCard) pre-WWW (p. 165)
  - Xerox PARC




New Dark Age by James Bridle
Verso 2018


Reading New Dark Age by James Bridle affirmed a pattern that I've been noticing across the handful of discplines that I follow — namely that computational complexity is making the world less legible despite the technological optimism that gives rise to the complexity in the first place.

Here's an example. I used to take the bus everywhere, and I've used various different bus systems in different sized cities across the United States. From my perspective as a passenger, the biggest problem that I saw with transportation was that there wasn't enough buses lines and the existing bus lines didn't operate at a high enough frequency to be useful. Now I live in a city that forces me to drive everywhere (although I've taken the bus here before, and it works fine in many circumstances). Recently, the tri-county area has been considering revamping the area's transportation options. Many transportation wonks in the area have been praising the rise of driverless cars or ride-sharing services as a solution to the lack of public transportation. From the perspective of someone who used transportation, it kind of sounds like misplaced technological optimism that leaves fundamental questions unanswered: Why would the absence of a human driver increase access to affordable transportation? How would ride-sharing be anymore efficient than a municipal or regional public transportation option? With the overhead of costs in researching and implementing such technological solutions, couldn't that money just go into more buses?

Looking at this discussion play out reminds me of a point that Bridle makes early on — the tools that we give ourselves to fix problems in the world govern the metaphors that we create for understanding those problems. Lately the tools that we've been using to imagine these problems involve a level of computational complexity that arguably paralyzes us from acting on the problems at hand. Bridle uses various examples throughout the book of how this computationally-intensive approaches have actually been less effictive in solving problems. My favorite example from the book is with drug discovery and the effects of Eroom's Law — where drug development has actually gotten slower despite all of the developments in computational solutions to finding new drugs. One potential cause for this trend is that there is less basic research and more brute-force testing with techniques like high-throughput screening. It used to be that there were small teams of specialists working on drug discovery where they would do phenotypic screening where you observe the effects of the drug first, and then investigate the target of action in the process called 'classical pharmacology'. With the rise of computational solutions, many labs now do 'reverse pharmacology' where they determine the target first, and then try to find compounds to act on that target and test them in bulk through processes like high-throughput screening. The first time that I discovered that this is how drug discovery happens, I was turned off from the field. What happened to chemists going on adventures to far away places in the world to find new plant molecules to treat diseases. Scientists used to have these neat specialties in small groups of compounds — for example, I had a chemist friend in college whose specialty was in complex organic acids produced by lichens. Nowadays drug discovery is governed by a group of computational hot-shot scientists that don't have any specialized knowledge in compounds, but rather approach the problem as a brute-force computational puzzle.

Another example that Bridle gives of the paralyzing ineffectiveness of complexity is that of surveillance. One one side, the power of modern governments to conduct surveillance on citizens at unprecedented scales has yielded relatively few leads relative to traditional surveillance methods. However, the same is true for countersurveillance efforts by organizations that expose and leak details of the innner-workings of governments that conduct the surveillance. When I first read this I was initially taken back, as I generally support these efforts at exposing these aspects of the government. How could more leaks be bad? Consider how many details have been leaked about government surveillance programs, and how complicated it all is. Few policy makers understood the details enough to follow the Snowden leaks. Many elected representatives don't even understand how browser cookies work. Yet we're still awash in the details of all leaks like this with the false impression that more information about a complicated problem will allow us to solve it in the end. In reality, these details give the situation a false facade of legibility, and if anything it's harder to act than ever. Bridle cites a strategy that Julian Assange lays out in his essay 'Conspiracy as Governance', where the effect of the leaks is to destabilize the organization that the leaks target. The goal has always been to use the leaks as a weapon, rather changing institutions. In this light, it makes sense that virtually no serious action has been taken to stop government serveillance, as that was never the point.

A main thesis of New Dark Age is that we're at an intellectual dead end after collecting so much data about our rapidly changing world. At first glance, it seems like kind of a bleak note to base a book around. Yet Bridle frames it as a problem of re-imagining the tools that he have at our disposal. We may actually already have the platforms and infrastrucure for solving the problems. Something that I'm hopeful for is that in addition to re-imagining our tools, we re-imagine some disciplines to allow for more creativity. Bridle cites a point that the biochemist Erwin Chargaff makes about the role of Homo ludens in science against the role of investors. We may just have to be more playful with the problems at hand in order to make for better solutions to them. The point is also to act on our data instead of thinking that data is the answer itself.



__Some notes__
- Technology is not just making tools, but making metaphores to understand the world (p. 13)
  - Project of re-imaginig our tools - make new metaphors to enchant/understand the world
  - When you're a hammer, everything looks like a nail
  - Peace Corps aid work - the problems have to be the ones that are legible to bureaucrats in Washington
    - We set out to have solutions to problems that we perceive through the lens of the technology that we want to deploy to fix it
    - See crop yield as the problems when we already know the solution - more pesticides/fertilizer
  - Taking the bus - a bunch of transportation apps try to pitch the driverless cars thing to help the transportation sector
    - But really the problem is that people don't have access to transport
    - Could be as simple as just having more bus lines so that people could travel for cheap
    - Instead we're looking to the tech sector to define the problems before just using the old fashioned solution
- Point in which computation slid out of view (p. 29)
  - Used to be that you could hear the parts of the process and know which parts of the problem the machin was working on
  - But eventually got so complex that you could have ballistics computations going on in plain sight in downtown New York
    - IBM SSEC New York 1948
- Now complexity and opacity renders the process as illegible (p. 40)
  - Gives rise to faith in the machine - automation bias
    - Value automated decision making over our own experiences even when it contradicts our own judgement 
  - Then amplified by confirmation bias - when we reshape our way of looking at the world to bring it in line with automated info
- Feedback: in nature - clear-air turbulence (p. 69)
  - We create more CO2 by flying planes, but that CO2 in the atmosphere creates more clear-air turbulence, making it harder to fly planes
- Computation making progress harder: Eroom's law with drugs (p. 93)
  - More and more computational power is going into develop drugs (like high-throughput screening)
  - But there's the trend that novel drug discovery is actually slowing down
  - Could be because the 'reverse pharmacology' approach of going from disease target molecule, and then try to find the thing that interacts with it
    - Contrary to 'classical pharmacology' where you test drugs in an animal model, and then if they work determine the target
  - 'Basic research/brute force' problem
    - High-throughput screening as a form of automation bias
    - Used to be small teams of specialists that studied groups of molecules - knowledge of specific types of chemicals
    - Now it's all automated testing against broad groups of chemicals
  - I always like specialists that know a bunch about individual groups of chemicals - like Molecule of the Month
    - They know so much about such a little group of things - lively group
      - Think about Rosco who knew a bunch about lichen acids
    - But know it's a bunch of computation hot-shot people that don't have that granular knowledge of small sub-fields
  - Computational pharmacology is documenting its decline
    - Erwin Chargaff (1974) - testifying about the decline of scientific imagination
      - Homo ludens dominated by corporate finance
      - Need to re-introduce Homo ludens (imagination/playfulness) into science
- Technology as a reification of a set of beliefs (p. 142)
  - Predictive policing - better at predicting policing practices than predicting crimes
  - Anything but neuatral - entangled in history
  - Possibly not even effective
- Does shedding more light on the problem of sureveillance actually fix it? (p. 180 - 184)
  - Sureveillance agencies see that collecting more data facillitates stopping bad things before they happen
    - But even internal reviews show that it's not essential to preventing attacks and that traditional leads worked just as well
  - When Snowden/Wikileaks expose inner workings, it gives us the false illusion of understanding and possibly countering their effects
    - We operate under the same logic of knowing more data can possibly counter the problem - but is that actually the case?
    - Same logic of transparency as antidote to secrecy
    - Even Assange states that the act of leaking itself is damaging to power, rather than the contents of the leak
  - Similar to climate crisis - where we're striving for 100% accuracy in our hypothesis before acting on it
    - Yet it's urgent, and gathering more data and trying to analyze it is preventing us from acting on it
- We're at an intellectual dead-end after gathering so much data (p. 248)











